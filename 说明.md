# cifar 案例

我用的是 torch 2.0

cd training/cifar/
pip install -r requirements.txt

python cifar10_tutorial.py

deepspeed cifar10_deepspeed.py --deepspeed

如果我没有编译 cuda op，训练时候还会自动编译？ `Loading extension module fused_adam...`

默认跑的是 zero-0，实际上就是普通 ddp，

deepspeed cifar10_deepspeed.py --deepspeed --stage 3

deepspeed 使用一共2步：

1. 注入一些 deepspeed 命令行参数
```python
parser = deepspeed.add_config_arguments(parser)
```

2. 初始化

```python
parameters = filter(lambda p: p.requires_grad, net.parameters())
args=add_argument()

 # Initialize DeepSpeed to use the following features
 # 1) Distributed model.
 # 2) Distributed data loader.
 # 3) DeepSpeed optimizer.
 model_engine, optimizer, trainloader, _ = deepspeed.initialize(args=args, model=net, model_parameters=parameters, training_data=trainset)
```

优化器，调度器等等设置，全部通过 json 文件控制

这个 json 文件内容，可以通过 `--deepspeed_config ds_config.json` 来传入，也可以直接在 initialize 时候传入，例如

```python
model_engine, optimizer, trainloader, __ = deepspeed.initialize(
    args=args, model=net, model_parameters=parameters, training_data=trainset, config=ds_config)
```

后续的一些常规代码全部由 deepspeed 接管，例如

```python
outputs = model_engine(inputs)
loss = criterion(outputs, labels)
model_engine.backward(loss)
model_engine.step()
```

因此简单来说，deepspeed 的核心就是这个 ds_config，用户修改的也都是这个配置文件，代码基本上都是一样的。

如果学习率调度等不想由 dp 接管，那么你可以不要传入这个配置参数。

